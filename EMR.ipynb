{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "discrete-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "solid-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\dell\\Desktop\\mp\\fer2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beautiful-joyce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   emotion  35887 non-null  int64 \n",
      " 1   pixels   35887 non-null  object\n",
      " 2   Usage    35887 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "strange-bradford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emotion                                             pixels     Usage\n",
      "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
      "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
      "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
      "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
      "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "green-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,train_y,X_test,test_y=[],[],[],[]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "           X_train.append(np.array(val,'float32'))\n",
    "           train_y.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "           X_test.append(np.array(val,'float32'))\n",
    "           test_y.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "arranged-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 7\n",
    "epochs = 100\n",
    "width, height = 48, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "increasing-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train,'float32')\n",
    "train_y = np.array(train_y,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "test_y = np.array(test_y,'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chronic-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "split-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "outside-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "##designing the cnn\n",
    "#1st convolution layer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(Conv2D(32,kernel_size= (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "important-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "federal-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nasty-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fully connected neural networks\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "massive-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compliling the model\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "seeing-disorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "225/225 [==============================] - 288s 1s/step - loss: 2.1281 - accuracy: 0.1992 - val_loss: 1.8323 - val_accuracy: 0.2522\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 291s 1s/step - loss: 1.7938 - accuracy: 0.2754 - val_loss: 1.6926 - val_accuracy: 0.3107\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 278s 1s/step - loss: 1.6498 - accuracy: 0.3411 - val_loss: 1.5489 - val_accuracy: 0.3859\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 1.5466 - accuracy: 0.3889 - val_loss: 1.5255 - val_accuracy: 0.3895\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 294s 1s/step - loss: 1.4529 - accuracy: 0.4329 - val_loss: 1.4051 - val_accuracy: 0.4581\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 286s 1s/step - loss: 1.3773 - accuracy: 0.4711 - val_loss: 1.2923 - val_accuracy: 0.4990\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 280s 1s/step - loss: 1.3035 - accuracy: 0.5020 - val_loss: 1.2632 - val_accuracy: 0.5155\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 293s 1s/step - loss: 1.2553 - accuracy: 0.5242 - val_loss: 1.2347 - val_accuracy: 0.5336\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 1.2144 - accuracy: 0.5400 - val_loss: 1.2216 - val_accuracy: 0.5311\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 1.1751 - accuracy: 0.5572 - val_loss: 1.1446 - val_accuracy: 0.5642\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 278s 1s/step - loss: 1.1359 - accuracy: 0.5745 - val_loss: 1.1403 - val_accuracy: 0.5667\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 277s 1s/step - loss: 1.1065 - accuracy: 0.5892 - val_loss: 1.1432 - val_accuracy: 0.5704\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 279s 1s/step - loss: 1.0864 - accuracy: 0.5965 - val_loss: 1.1239 - val_accuracy: 0.5681\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 277s 1s/step - loss: 1.0427 - accuracy: 0.6132 - val_loss: 1.1591 - val_accuracy: 0.5603\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 277s 1s/step - loss: 1.0240 - accuracy: 0.6214 - val_loss: 1.1101 - val_accuracy: 0.5754\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 277s 1s/step - loss: 0.9971 - accuracy: 0.6322 - val_loss: 1.1202 - val_accuracy: 0.5896\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 283s 1s/step - loss: 0.9662 - accuracy: 0.6451 - val_loss: 1.1229 - val_accuracy: 0.5885\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 313s 1s/step - loss: 0.9345 - accuracy: 0.6568 - val_loss: 1.1023 - val_accuracy: 0.5946\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.9176 - accuracy: 0.6652 - val_loss: 1.0997 - val_accuracy: 0.5860\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 278s 1s/step - loss: 0.8841 - accuracy: 0.6775 - val_loss: 1.1243 - val_accuracy: 0.5857\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 278s 1s/step - loss: 0.8719 - accuracy: 0.6827 - val_loss: 1.1115 - val_accuracy: 0.5935\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.8338 - accuracy: 0.6972 - val_loss: 1.1620 - val_accuracy: 0.5860\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.8192 - accuracy: 0.7051 - val_loss: 1.1431 - val_accuracy: 0.5996\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.8015 - accuracy: 0.7085 - val_loss: 1.1477 - val_accuracy: 0.6032\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 274s 1s/step - loss: 0.7705 - accuracy: 0.7212 - val_loss: 1.1205 - val_accuracy: 0.6027\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 274s 1s/step - loss: 0.7523 - accuracy: 0.7274 - val_loss: 1.1684 - val_accuracy: 0.6069\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 277s 1s/step - loss: 0.7400 - accuracy: 0.7336 - val_loss: 1.1462 - val_accuracy: 0.5952\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.7147 - accuracy: 0.7422 - val_loss: 1.1485 - val_accuracy: 0.6021\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.6957 - accuracy: 0.7524 - val_loss: 1.1957 - val_accuracy: 0.6041\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 274s 1s/step - loss: 0.6796 - accuracy: 0.7573 - val_loss: 1.1963 - val_accuracy: 0.6010\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.6578 - accuracy: 0.7673 - val_loss: 1.2205 - val_accuracy: 0.5993\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 274s 1s/step - loss: 0.6437 - accuracy: 0.7687 - val_loss: 1.2513 - val_accuracy: 0.6013\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 277s 1s/step - loss: 0.6263 - accuracy: 0.7774 - val_loss: 1.2203 - val_accuracy: 0.6021\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.6044 - accuracy: 0.7839 - val_loss: 1.2428 - val_accuracy: 0.6052\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 274s 1s/step - loss: 0.5946 - accuracy: 0.7884 - val_loss: 1.2419 - val_accuracy: 0.6055\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.5796 - accuracy: 0.7941 - val_loss: 1.2532 - val_accuracy: 0.6108\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 277s 1s/step - loss: 0.5698 - accuracy: 0.7988 - val_loss: 1.2362 - val_accuracy: 0.6110\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.5562 - accuracy: 0.8030 - val_loss: 1.2435 - val_accuracy: 0.6094\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.5362 - accuracy: 0.8102 - val_loss: 1.2948 - val_accuracy: 0.6010\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.5302 - accuracy: 0.8113 - val_loss: 1.3132 - val_accuracy: 0.6110\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 274s 1s/step - loss: 0.5171 - accuracy: 0.8166 - val_loss: 1.3022 - val_accuracy: 0.6091\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.5045 - accuracy: 0.8196 - val_loss: 1.3311 - val_accuracy: 0.6027\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.4973 - accuracy: 0.8236 - val_loss: 1.3388 - val_accuracy: 0.6119\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.4814 - accuracy: 0.8339 - val_loss: 1.3536 - val_accuracy: 0.6082\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.4719 - accuracy: 0.8360 - val_loss: 1.3517 - val_accuracy: 0.6055\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 278s 1s/step - loss: 0.4665 - accuracy: 0.8355 - val_loss: 1.3293 - val_accuracy: 0.6077\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.4500 - accuracy: 0.8426 - val_loss: 1.3565 - val_accuracy: 0.6138\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.4537 - accuracy: 0.8428 - val_loss: 1.4252 - val_accuracy: 0.5904\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.4460 - accuracy: 0.8436 - val_loss: 1.3449 - val_accuracy: 0.6138\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.4289 - accuracy: 0.8494 - val_loss: 1.3835 - val_accuracy: 0.6222\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.4114 - accuracy: 0.8562 - val_loss: 1.4126 - val_accuracy: 0.6124\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.4121 - accuracy: 0.8552 - val_loss: 1.4007 - val_accuracy: 0.6071\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.4114 - accuracy: 0.8562 - val_loss: 1.3810 - val_accuracy: 0.6155\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.4022 - accuracy: 0.8576 - val_loss: 1.4293 - val_accuracy: 0.5935\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.3873 - accuracy: 0.8641 - val_loss: 1.4952 - val_accuracy: 0.6046\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.3879 - accuracy: 0.8627 - val_loss: 1.4801 - val_accuracy: 0.6002\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 275s 1s/step - loss: 0.3793 - accuracy: 0.8678 - val_loss: 1.4518 - val_accuracy: 0.6052\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 274s 1s/step - loss: 0.4388 - accuracy: 0.8477 - val_loss: 1.4439 - val_accuracy: 0.6057\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 277s 1s/step - loss: 0.3810 - accuracy: 0.8672 - val_loss: 1.4611 - val_accuracy: 0.6046\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.3514 - accuracy: 0.8771 - val_loss: 1.4895 - val_accuracy: 0.6127\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 273s 1s/step - loss: 0.3629 - accuracy: 0.8729 - val_loss: 1.5224 - val_accuracy: 0.6096\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 300s 1s/step - loss: 0.3452 - accuracy: 0.8816 - val_loss: 1.5067 - val_accuracy: 0.6063\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 327s 1s/step - loss: 0.3441 - accuracy: 0.8820 - val_loss: 1.5051 - val_accuracy: 0.6082\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 327s 1s/step - loss: 0.3433 - accuracy: 0.8812 - val_loss: 1.6096 - val_accuracy: 0.5993\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 330s 1s/step - loss: 0.3355 - accuracy: 0.8839 - val_loss: 1.4477 - val_accuracy: 0.6105\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 329s 1s/step - loss: 0.3267 - accuracy: 0.8881 - val_loss: 1.5573 - val_accuracy: 0.6105\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 330s 1s/step - loss: 0.3262 - accuracy: 0.8860 - val_loss: 1.5040 - val_accuracy: 0.6141\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 330s 1s/step - loss: 0.3148 - accuracy: 0.8912 - val_loss: 1.4769 - val_accuracy: 0.6096\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 330s 1s/step - loss: 0.3150 - accuracy: 0.8914 - val_loss: 1.6243 - val_accuracy: 0.6077\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 329s 1s/step - loss: 0.3169 - accuracy: 0.8919 - val_loss: 1.5325 - val_accuracy: 0.6119\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 328s 1s/step - loss: 0.3103 - accuracy: 0.8948 - val_loss: 1.5400 - val_accuracy: 0.6004\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 328s 1s/step - loss: 0.3073 - accuracy: 0.8944 - val_loss: 1.5655 - val_accuracy: 0.6063\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 329s 1s/step - loss: 0.3094 - accuracy: 0.8951 - val_loss: 1.5368 - val_accuracy: 0.6071\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 328s 1s/step - loss: 0.3019 - accuracy: 0.8965 - val_loss: 1.5847 - val_accuracy: 0.6041\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 328s 1s/step - loss: 0.2998 - accuracy: 0.8965 - val_loss: 1.5820 - val_accuracy: 0.6071\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 328s 1s/step - loss: 0.2878 - accuracy: 0.8997 - val_loss: 1.6267 - val_accuracy: 0.6057\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 312s 1s/step - loss: 0.2886 - accuracy: 0.9012 - val_loss: 1.5920 - val_accuracy: 0.6124\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.2874 - accuracy: 0.9043 - val_loss: 1.6173 - val_accuracy: 0.6110\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.2783 - accuracy: 0.9029 - val_loss: 1.5954 - val_accuracy: 0.6116\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.2777 - accuracy: 0.9054 - val_loss: 1.5709 - val_accuracy: 0.6119\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 274s 1s/step - loss: 0.2904 - accuracy: 0.8992 - val_loss: 1.5576 - val_accuracy: 0.6169\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.2762 - accuracy: 0.9036 - val_loss: 1.6276 - val_accuracy: 0.6102\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.2716 - accuracy: 0.9057 - val_loss: 1.6709 - val_accuracy: 0.6133\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 280s 1s/step - loss: 0.2647 - accuracy: 0.9094 - val_loss: 1.6341 - val_accuracy: 0.6160\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 283s 1s/step - loss: 0.2647 - accuracy: 0.9107 - val_loss: 1.6319 - val_accuracy: 0.6252\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 277s 1s/step - loss: 0.2595 - accuracy: 0.9097 - val_loss: 1.6143 - val_accuracy: 0.6094\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 279s 1s/step - loss: 0.2574 - accuracy: 0.9115 - val_loss: 1.6326 - val_accuracy: 0.6158\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.2515 - accuracy: 0.9127 - val_loss: 1.6668 - val_accuracy: 0.6144\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 274s 1s/step - loss: 0.2518 - accuracy: 0.9155 - val_loss: 1.7097 - val_accuracy: 0.5960\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.2531 - accuracy: 0.9156 - val_loss: 1.6667 - val_accuracy: 0.6180\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.2548 - accuracy: 0.9134 - val_loss: 1.6196 - val_accuracy: 0.6191\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.2438 - accuracy: 0.9159 - val_loss: 1.6934 - val_accuracy: 0.6105\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.2416 - accuracy: 0.9158 - val_loss: 1.7034 - val_accuracy: 0.6108\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.2416 - accuracy: 0.9180 - val_loss: 1.6788 - val_accuracy: 0.6119\n",
      "Epoch 95/100\n",
      "225/225 [==============================] - 276s 1s/step - loss: 0.2419 - accuracy: 0.9181 - val_loss: 1.6967 - val_accuracy: 0.6077\n",
      "Epoch 96/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.2407 - accuracy: 0.9166 - val_loss: 1.6260 - val_accuracy: 0.6121\n",
      "Epoch 97/100\n",
      "225/225 [==============================] - 278s 1s/step - loss: 0.2345 - accuracy: 0.9203 - val_loss: 1.6605 - val_accuracy: 0.6082\n",
      "Epoch 98/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.2340 - accuracy: 0.9184 - val_loss: 1.6956 - val_accuracy: 0.6052\n",
      "Epoch 99/100\n",
      "225/225 [==============================] - 275s 1s/step - loss: 0.2356 - accuracy: 0.9216 - val_loss: 1.6544 - val_accuracy: 0.6160\n",
      "Epoch 100/100\n",
      "225/225 [==============================] - 274s 1s/step - loss: 0.2291 - accuracy: 0.9202 - val_loss: 1.7124 - val_accuracy: 0.6130\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, train_y,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True)\n",
    "\n",
    "\n",
    "#Saving the  model to  use it later on\n",
    "model.save_weights(\"fer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "attached-contrast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9201644062995911\n",
      "Validation Accuracy:  0.6129841208457947\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 1.7124 - accuracy: 0.6130 0s - loss: 1.7356 - \n",
      "Test accuracy: 0.6129841208457947\n"
     ]
    }
   ],
   "source": [
    "train_acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "print('Training Accuracy: ', train_acc[-1])\n",
    "print('Validation Accuracy: ', val_acc[-1])\n",
    "\n",
    "# test loss and accuracy\n",
    "score, acc = model.evaluate(X_test, test_y,\n",
    "                            batch_size=32)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-score",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
