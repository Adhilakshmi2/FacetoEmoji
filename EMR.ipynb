{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "discrete-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "solid-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\dell\\Desktop\\mp\\fer2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beautiful-joyce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   emotion  35887 non-null  int64 \n",
      " 1   pixels   35887 non-null  object\n",
      " 2   Usage    35887 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "strange-bradford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emotion                                             pixels     Usage\n",
      "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
      "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
      "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
      "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
      "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "green-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,train_y,X_test,test_y=[],[],[],[]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "           X_train.append(np.array(val,'float32'))\n",
    "           train_y.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "           X_test.append(np.array(val,'float32'))\n",
    "           test_y.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "arranged-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 7\n",
    "epochs = 100\n",
    "width, height = 48, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "increasing-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train,'float32')\n",
    "train_y = np.array(train_y,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "test_y = np.array(test_y,'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "chronic-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "split-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train -= np.mean(X_train, axis=0)\n",
    "#X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "#X_test -= np.mean(X_test, axis=0)\n",
    "#X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "outside-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "##designing the cnn\n",
    "#1st convolution layer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(Conv2D(32,kernel_size= (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "important-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "federal-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "nasty-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fully connected neural networks\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "rough-rainbow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 46, 46, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 44, 44, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 44, 44, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 20, 20, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 18, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 18, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 5, 5, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 1799      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 555,111\n",
      "Trainable params: 553,127\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "massive-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compliling the model\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "seeing-disorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "225/225 [==============================] - 292s 1s/step - loss: 2.1476 - accuracy: 0.1970 - val_loss: 1.7817 - val_accuracy: 0.2605\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 1.8620 - accuracy: 0.2374 - val_loss: 1.7973 - val_accuracy: 0.2561\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 265s 1s/step - loss: 1.6986 - accuracy: 0.3188 - val_loss: 1.6478 - val_accuracy: 0.3410\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 1.5516 - accuracy: 0.3828 - val_loss: 1.5442 - val_accuracy: 0.3845\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 1.4610 - accuracy: 0.4285 - val_loss: 1.6378 - val_accuracy: 0.3399\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 1.3722 - accuracy: 0.4698 - val_loss: 1.3912 - val_accuracy: 0.4575\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 277s 1s/step - loss: 1.3082 - accuracy: 0.4982 - val_loss: 1.3151 - val_accuracy: 0.4962\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 1.2713 - accuracy: 0.5138 - val_loss: 1.2582 - val_accuracy: 0.5132\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 1.2369 - accuracy: 0.5286 - val_loss: 1.2451 - val_accuracy: 0.5174\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 1.1994 - accuracy: 0.5437 - val_loss: 1.1763 - val_accuracy: 0.5464\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 1.1626 - accuracy: 0.5586 - val_loss: 1.2424 - val_accuracy: 0.5280\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 281s 1s/step - loss: 1.1366 - accuracy: 0.5717 - val_loss: 1.2362 - val_accuracy: 0.5408\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 1.1066 - accuracy: 0.5846 - val_loss: 1.1696 - val_accuracy: 0.5517\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 1.0784 - accuracy: 0.5947 - val_loss: 1.2099 - val_accuracy: 0.5453\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 1.0485 - accuracy: 0.6062 - val_loss: 1.1927 - val_accuracy: 0.5478\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 265s 1s/step - loss: 1.0180 - accuracy: 0.6236 - val_loss: 1.1261 - val_accuracy: 0.5834\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.9927 - accuracy: 0.6307 - val_loss: 1.1398 - val_accuracy: 0.5745\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.9646 - accuracy: 0.6432 - val_loss: 1.3362 - val_accuracy: 0.5238\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 273s 1s/step - loss: 0.9815 - accuracy: 0.6396 - val_loss: 1.1059 - val_accuracy: 0.5918\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 270s 1s/step - loss: 0.9211 - accuracy: 0.6600 - val_loss: 1.1072 - val_accuracy: 0.5954\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.9005 - accuracy: 0.6683 - val_loss: 1.0987 - val_accuracy: 0.5940\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.8726 - accuracy: 0.6817 - val_loss: 1.1773 - val_accuracy: 0.5793\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 265s 1s/step - loss: 0.8470 - accuracy: 0.6928 - val_loss: 1.0953 - val_accuracy: 0.6043\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.8310 - accuracy: 0.6981 - val_loss: 1.0871 - val_accuracy: 0.6169\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 265s 1s/step - loss: 0.8060 - accuracy: 0.7067 - val_loss: 1.3192 - val_accuracy: 0.5442\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.7888 - accuracy: 0.7166 - val_loss: 1.1286 - val_accuracy: 0.6149\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 273s 1s/step - loss: 0.7617 - accuracy: 0.7249 - val_loss: 1.1833 - val_accuracy: 0.5901\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 320s 1s/step - loss: 0.7453 - accuracy: 0.7317 - val_loss: 1.1462 - val_accuracy: 0.6138\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 329s 1s/step - loss: 0.7141 - accuracy: 0.7428 - val_loss: 1.2000 - val_accuracy: 0.6063\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 319s 1s/step - loss: 0.7117 - accuracy: 0.7446 - val_loss: 1.1737 - val_accuracy: 0.6144\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 334s 1s/step - loss: 0.6837 - accuracy: 0.7563 - val_loss: 1.1566 - val_accuracy: 0.6188\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 326s 1s/step - loss: 0.6703 - accuracy: 0.7624 - val_loss: 1.3271 - val_accuracy: 0.5751\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.6621 - accuracy: 0.7640 - val_loss: 1.2394 - val_accuracy: 0.5940\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.6547 - accuracy: 0.7661 - val_loss: 1.2104 - val_accuracy: 0.6016\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 272s 1s/step - loss: 0.6123 - accuracy: 0.7827 - val_loss: 1.2165 - val_accuracy: 0.6119\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 279s 1s/step - loss: 0.6005 - accuracy: 0.7856 - val_loss: 1.2048 - val_accuracy: 0.6138\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.6050 - accuracy: 0.7852 - val_loss: 1.2583 - val_accuracy: 0.6016\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 272s 1s/step - loss: 0.5810 - accuracy: 0.7963 - val_loss: 1.1955 - val_accuracy: 0.6158\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.5649 - accuracy: 0.8014 - val_loss: 1.2359 - val_accuracy: 0.5988\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.5551 - accuracy: 0.8049 - val_loss: 1.2800 - val_accuracy: 0.6121\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.5453 - accuracy: 0.8065 - val_loss: 1.2557 - val_accuracy: 0.6066\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.5300 - accuracy: 0.8136 - val_loss: 1.3206 - val_accuracy: 0.5949\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 272s 1s/step - loss: 0.5154 - accuracy: 0.8206 - val_loss: 1.3210 - val_accuracy: 0.5938\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.5116 - accuracy: 0.8208 - val_loss: 1.3075 - val_accuracy: 0.6046\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 270s 1s/step - loss: 0.5011 - accuracy: 0.8240 - val_loss: 1.3643 - val_accuracy: 0.6105\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.4982 - accuracy: 0.8262 - val_loss: 1.3447 - val_accuracy: 0.6016\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.4814 - accuracy: 0.8302 - val_loss: 1.3747 - val_accuracy: 0.5940\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.4759 - accuracy: 0.8320 - val_loss: 1.3615 - val_accuracy: 0.6066\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.4601 - accuracy: 0.8404 - val_loss: 1.3368 - val_accuracy: 0.6018\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.4596 - accuracy: 0.8398 - val_loss: 1.3138 - val_accuracy: 0.6124\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.4444 - accuracy: 0.8441 - val_loss: 1.3530 - val_accuracy: 0.6130\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.4297 - accuracy: 0.8500 - val_loss: 1.4176 - val_accuracy: 0.6091\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.4310 - accuracy: 0.8513 - val_loss: 1.3514 - val_accuracy: 0.6239\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.4202 - accuracy: 0.8547 - val_loss: 1.4526 - val_accuracy: 0.5899\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 269s 1s/step - loss: 0.4134 - accuracy: 0.8548 - val_loss: 1.4456 - val_accuracy: 0.6166\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.4101 - accuracy: 0.8589 - val_loss: 1.4391 - val_accuracy: 0.6049\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 266s 1s/step - loss: 0.3969 - accuracy: 0.8607 - val_loss: 1.5032 - val_accuracy: 0.6127\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.3931 - accuracy: 0.8635 - val_loss: 1.4498 - val_accuracy: 0.6208\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.3830 - accuracy: 0.8659 - val_loss: 1.4575 - val_accuracy: 0.6088\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.3813 - accuracy: 0.8649 - val_loss: 1.4285 - val_accuracy: 0.6121\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.3832 - accuracy: 0.8683 - val_loss: 1.4655 - val_accuracy: 0.6113\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.3748 - accuracy: 0.8691 - val_loss: 1.4708 - val_accuracy: 0.6152\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.3694 - accuracy: 0.8712 - val_loss: 1.5206 - val_accuracy: 0.5979\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.3591 - accuracy: 0.8763 - val_loss: 1.4734 - val_accuracy: 0.6160\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.3561 - accuracy: 0.8761 - val_loss: 1.5122 - val_accuracy: 0.6172\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 274s 1s/step - loss: 0.3529 - accuracy: 0.8767 - val_loss: 1.5113 - val_accuracy: 0.6082\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.3511 - accuracy: 0.8778 - val_loss: 1.4452 - val_accuracy: 0.6105\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 285s 1s/step - loss: 0.3557 - accuracy: 0.8780 - val_loss: 1.4636 - val_accuracy: 0.6158\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.3428 - accuracy: 0.8814 - val_loss: 1.5091 - val_accuracy: 0.6133\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.3420 - accuracy: 0.8827 - val_loss: 1.4946 - val_accuracy: 0.6094\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.3299 - accuracy: 0.8856 - val_loss: 1.5224 - val_accuracy: 0.6094\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.3193 - accuracy: 0.8906 - val_loss: 1.5837 - val_accuracy: 0.6116\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.3260 - accuracy: 0.8879 - val_loss: 1.5305 - val_accuracy: 0.6250\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.3192 - accuracy: 0.8887 - val_loss: 1.5306 - val_accuracy: 0.6133\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.3064 - accuracy: 0.8954 - val_loss: 1.5358 - val_accuracy: 0.6135\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.3074 - accuracy: 0.8939 - val_loss: 1.5902 - val_accuracy: 0.6102\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 266s 1s/step - loss: 0.3105 - accuracy: 0.8937 - val_loss: 1.5885 - val_accuracy: 0.6119\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 281s 1s/step - loss: 0.3085 - accuracy: 0.8940 - val_loss: 1.5268 - val_accuracy: 0.6163\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 269s 1s/step - loss: 0.2980 - accuracy: 0.8977 - val_loss: 1.5471 - val_accuracy: 0.6294\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 270s 1s/step - loss: 0.2900 - accuracy: 0.8988 - val_loss: 1.5823 - val_accuracy: 0.6041\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 269s 1s/step - loss: 0.2879 - accuracy: 0.9023 - val_loss: 1.5789 - val_accuracy: 0.6152\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.2944 - accuracy: 0.9001 - val_loss: 1.5907 - val_accuracy: 0.6149\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.2972 - accuracy: 0.8973 - val_loss: 1.5579 - val_accuracy: 0.6180\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 269s 1s/step - loss: 0.2862 - accuracy: 0.9029 - val_loss: 1.5543 - val_accuracy: 0.6239\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 269s 1s/step - loss: 0.2792 - accuracy: 0.9052 - val_loss: 1.5443 - val_accuracy: 0.6241\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.2820 - accuracy: 0.9029 - val_loss: 1.5875 - val_accuracy: 0.6085\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.2771 - accuracy: 0.9051 - val_loss: 1.6405 - val_accuracy: 0.6152\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.2609 - accuracy: 0.9141 - val_loss: 1.6478 - val_accuracy: 0.6133\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.2707 - accuracy: 0.9067 - val_loss: 1.6528 - val_accuracy: 0.6219\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 272s 1s/step - loss: 0.2629 - accuracy: 0.9097 - val_loss: 1.6266 - val_accuracy: 0.6133\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.2695 - accuracy: 0.9066 - val_loss: 1.6914 - val_accuracy: 0.6172\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 269s 1s/step - loss: 0.2676 - accuracy: 0.9078 - val_loss: 1.6270 - val_accuracy: 0.6066\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.2565 - accuracy: 0.9132 - val_loss: 1.6884 - val_accuracy: 0.6080\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 271s 1s/step - loss: 0.2592 - accuracy: 0.9099 - val_loss: 1.6250 - val_accuracy: 0.6169\n",
      "Epoch 95/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.2623 - accuracy: 0.9114 - val_loss: 1.6277 - val_accuracy: 0.6205\n",
      "Epoch 96/100\n",
      "225/225 [==============================] - 267s 1s/step - loss: 0.2489 - accuracy: 0.9142 - val_loss: 1.7004 - val_accuracy: 0.6060\n",
      "Epoch 97/100\n",
      "225/225 [==============================] - 269s 1s/step - loss: 0.2558 - accuracy: 0.9133 - val_loss: 1.6677 - val_accuracy: 0.6110\n",
      "Epoch 98/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.2575 - accuracy: 0.9139 - val_loss: 1.6626 - val_accuracy: 0.6149\n",
      "Epoch 99/100\n",
      "225/225 [==============================] - 268s 1s/step - loss: 0.2526 - accuracy: 0.9145 - val_loss: 1.6031 - val_accuracy: 0.6211\n",
      "Epoch 100/100\n",
      "225/225 [==============================] - 270s 1s/step - loss: 0.2552 - accuracy: 0.9138 - val_loss: 1.6481 - val_accuracy: 0.6133\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, train_y,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True)\n",
    "\n",
    "\n",
    "#Saving the  model to  use it later on\n",
    "model.save_weights(\"fer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "attached-contrast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9137552976608276\n",
      "Validation Accuracy:  0.6132627725601196\n",
      "113/113 [==============================] - 7s 64ms/step - loss: 1.6481 - accuracy: 0.6133\n",
      "Test accuracy: 0.6132627725601196\n"
     ]
    }
   ],
   "source": [
    "train_acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "print('Training Accuracy: ', train_acc[-1])\n",
    "print('Validation Accuracy: ', val_acc[-1])\n",
    "\n",
    "# test loss and accuracy\n",
    "score, acc = model.evaluate(X_test, test_y,\n",
    "                            batch_size=32)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-score",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
